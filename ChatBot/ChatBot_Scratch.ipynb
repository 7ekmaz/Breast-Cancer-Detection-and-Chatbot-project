{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-UO2pcxxmDS"
      },
      "source": [
        " # **ChatBot From Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "124HANu54Dul"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoaAxpSoxPyc"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joGmdaZ86r_3"
      },
      "outputs": [],
      "source": [
        "#pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAQUbN157ovz"
      },
      "source": [
        "## Our workflow\n",
        "\n",
        "*   Read Chatbot corpus (Wikipedia About Breast Cancer ) + Lowering\n",
        "*   Tokenization\n",
        "*   Remove Stop words\n",
        "*   Preprocessing (Lemmatization)\n",
        "    * Lemmatization\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm3NnV0b8yyU"
      },
      "source": [
        "## **Read Corpus**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9dYRPnT9CxO"
      },
      "source": [
        "We will use a corpus from Wikipedia page about Breast Cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEsN4IXm84YE"
      },
      "outputs": [],
      "source": [
        "f = open('/content/Breast Cancer QnA.txt', 'r', errors = 'ignore')\n",
        "raw = f.read()\n",
        "raw = raw.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaYCAKxbFHbY",
        "outputId": "71329779-179a-47e9-e16d-b1ae5345c78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q1: what is breast cancer?\n",
            "a1: breast cancer is a disease in which cells in the breast grow uncontrollably. it can occur in the ducts, lobules, or\n",
            "other parts of the breast tissue.\n",
            "q2: what are the main types of breast cancer?\n",
            "a2: the main types include invasive ductal carcinoma, invasive lobular carcinoma, ductal carcinoma in situ (dcis),\n",
            "and triple-negative breast cancer.\n",
            "q3: what causes breast cancer?\n",
            "a3: the exact cause is unknown, but factors like genetic mutations, hormonal changes, and en\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "raw = re.sub(r'\\[\\d+\\]', '', raw)\n",
        "\n",
        "\n",
        "# Print the cleaned corpus\n",
        "print(raw[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yQw8Lwm4I9B"
      },
      "outputs": [],
      "source": [
        "def save_text_to_file(text, filename=\"output.txt\"):\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(text)\n",
        "\n",
        "save_text_to_file(raw, filename=\"output.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7-tOxJpFQYq",
        "outputId": "4e28c843-fdaa-4426-ed3a-0b00af6eaccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lar8XfuDf77",
        "outputId": "93f4ba61-2b93-4ec8-8ea1-959bbcd5f027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#-----------------------------\n",
        "\n",
        "nltk.download('popular', quiet=True) # for downloading packages\n",
        "nltk.download('punkt', quiet=True) # first-time use only\n",
        "nltk.download('punkt_tab', quiet=True) # first-time use only\n",
        "nltk.download('wordnet', quiet=True) # first-time use only\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Ki2t7XF3uD",
        "outputId": "5503a8c2-eab6-4fcd-f9ad-fac1a706fe11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt', force=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETOP54gGDMlh"
      },
      "source": [
        "## **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIJCZlzq7m8i"
      },
      "outputs": [],
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences\n",
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqDdpRvA4Lc0"
      },
      "outputs": [],
      "source": [
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzkyJQG24T_t"
      },
      "outputs": [],
      "source": [
        "word_tokens[:2]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N2RQZI_F6nA"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCNdXXy27hi7"
      },
      "outputs": [],
      "source": [
        "lemmer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(word_tokenize(text.lower().translate(remove_punct_dict)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rnajanslMI"
      },
      "source": [
        "## **Keyword Matching**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WozkiCVsskz-"
      },
      "outputs": [],
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        "\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzfdO84hKVQz"
      },
      "source": [
        "## **Word2Vec Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uksyDWS5Kr3W"
      },
      "outputs": [],
      "source": [
        "processed_corpus = [LemNormalize(sent) for sent in sent_tokens]  # Preprocess each sentence\n",
        "word2vec_model = Word2Vec(sentences=processed_corpus, vector_size=200, window=25 , min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsZZrTXqxLFT"
      },
      "outputs": [],
      "source": [
        "# Helper to get the embedding of a sentence\n",
        "def get_sentence_embedding(sentence, model):\n",
        "    words = LemNormalize(sentence)\n",
        "    embedding = np.mean([model.wv[word] for word in words if word in model.wv], axis=0)\n",
        "    return embedding if isinstance(embedding, np.ndarray) else np.zeros(model.vector_size)\n",
        "\n",
        "# Compute embeddings for all sentences in the corpus\n",
        "corpus_embeddings = [get_sentence_embedding(sent, word2vec_model) for sent in sent_tokens]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrxfExCiyHAC"
      },
      "source": [
        "## **Generate Responses**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuHs9rvuxLCE"
      },
      "outputs": [],
      "source": [
        "## First Approuch\n",
        "\n",
        "\n",
        "# Re-tokenize the corpus by paragraphs\n",
        "para_tokens = raw.split('\\n\\n')  # Assuming paragraphs are separated by double newlines\n",
        "corpus_embeddings = [get_sentence_embedding(para, word2vec_model) for para in para_tokens]\n",
        "\n",
        "def response(user_response):\n",
        "    chatbot_response = ''\n",
        "    user_embedding = get_sentence_embedding(user_response, word2vec_model)\n",
        "\n",
        "    # Calculate cosine similarity with corpus embeddings\n",
        "    similarities = cosine_similarity([user_embedding], corpus_embeddings)\n",
        "    idx = np.argmax(similarities)\n",
        "\n",
        "    # Check similarity threshold\n",
        "    if similarities[0][idx] < 0.2:  # Adjust this threshold if needed\n",
        "        chatbot_response = \"I am sorry! I don't understand you.\"\n",
        "    else:\n",
        "        chatbot_response = para_tokens[idx]  # Return the most similar paragraph\n",
        "\n",
        "    return chatbot_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sitb8rN8AV1-"
      },
      "outputs": [],
      "source": [
        "## Second approatch\n",
        "\n",
        "\n",
        "def response(user_response):\n",
        "    chatbot_response = ''\n",
        "    user_embedding = get_sentence_embedding(user_response, word2vec_model)\n",
        "\n",
        "    # Calculate cosine similarity with corpus embeddings\n",
        "    similarities = cosine_similarity([user_embedding], corpus_embeddings)\n",
        "    idx = np.argmax(similarities)\n",
        "\n",
        "    # Check similarity threshold\n",
        "    if similarities[0][idx] < 0.2:  # Adjust this threshold if needed\n",
        "        chatbot_response = \"I am sorry! I don't understand you.\"\n",
        "    else:\n",
        "        # Include the neighboring sentences for context\n",
        "        start_idx = max(0, idx - 1)\n",
        "        end_idx = min(len(sent_tokens), idx + 2)  # Adjust to include more or fewer sentences\n",
        "        chatbot_response = \" \".join(sent_tokens[start_idx:end_idx])\n",
        "\n",
        "    return chatbot_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlWTuUrECbIi"
      },
      "outputs": [],
      "source": [
        "## Third approach\n",
        "def response(user_response, top_k=3):\n",
        "    chatbot_response = ''\n",
        "    user_embedding = get_sentence_embedding(user_response, word2vec_model)\n",
        "\n",
        "    # Calculate cosine similarity with corpus embeddings\n",
        "    similarities = cosine_similarity([user_embedding], corpus_embeddings)[0]\n",
        "\n",
        "    # Get the indices of the top-k similar sentences\n",
        "    top_k_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    # Construct the response from top-k similar sentences\n",
        "    chatbot_response = \" \".join([sent_tokens[idx] for idx in top_k_indices if similarities[idx] > 0.2])  # Adjust threshold if needed\n",
        "\n",
        "    if not chatbot_response:\n",
        "        chatbot_response = \"I am sorry! I don't understand you.\"\n",
        "\n",
        "    return chatbot_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmFFT-QsxK-b"
      },
      "outputs": [],
      "source": [
        "# Chat Loop\n",
        "if __name__ == \"__main__\":\n",
        "    flag = True\n",
        "    print(\"Hello, there my name is Aneka. I will answer your queries. If you want to exit, type Bye!\")\n",
        "    while flag:\n",
        "        user_response = input(\"You: \").lower()\n",
        "        if user_response != 'bye':\n",
        "            if user_response == 'thanks' or user_response == 'thank you':\n",
        "                flag = False\n",
        "                print(\"Aneka: You're welcome!\")\n",
        "            else:\n",
        "                if greeting(user_response) is not None:\n",
        "                    print(\"Aneka:\", greeting(user_response))\n",
        "                else:\n",
        "                    print(\"Aneka:\", response(user_response))\n",
        "        else:\n",
        "            flag = False\n",
        "            print(\"Aneka: Bye! Have a great time!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj2Q6QHmcdOd"
      },
      "source": [
        "# First\n",
        "Aneka: breast cancer is a disease in which cells in the breast grow out of control. there are different types of breast cancer, and the type depends on which cells in the breast turn into cancer. breast cancer can begin in different parts of the breast, including the ducts, lobules, or in some cases, the tissue in between. while it primarily affects women, men can also develop breast cancer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS5DnFmCcosm"
      },
      "source": [
        "# Second\n",
        "Aneka: breast cancer is a disease in which cells in the breast grow out of control. there are different types of breast cancer, and the type depends on which cells in the breast turn into cancer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbSsJ2tXdsjf"
      },
      "source": [
        "# Third\n",
        "Aneka: breast cancer is a disease in which cells in the breast grow out of control. there are different types of breast cancer, and the type depends on which cells in the breast turn into cancer. breast cancer most commonly develops in cells from the lining of milk ducts and the lobules that supply these ducts with milk.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDNAIBikxK2L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ntjZ11DQe8W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWNvJPXJQe45"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ICJFZooQe2L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py0Hl8mgQezK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4gdgNc6QewN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-dEy-JEQ0WD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "8JuQiPLCQeta",
        "outputId": "af682254-7761-43c3-96e2-9f91bd508db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I’m here to help. Type 'bye' to exit.\n",
            "You: hello\n",
            "Chatbot: I’m sorry! I don’t understand you.\n",
            "You: what are types of breast cancer?\n",
            "Chatbot: there are different types of breast cancer, and the type depends on which cells in the breast turn into cancer.\n",
            "You: what are they?\n",
            "Chatbot: I’m sorry! I don’t understand you.\n",
            "You: what is the pink ribbon?\n",
            "Chatbot: pink ribbon\n",
            "a pink ribbon is the most prominent symbol of breast cancer awareness.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-92ea70c635f8>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello! I’m here to help. Type 'bye' to exit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot: Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Load and preprocess document\n",
        "#raw_document = \"\"\"Your single document text goes here...\"\"\"  # Load your document text here\n",
        "sent_tokens = nltk.sent_tokenize(raw)  # Split document into sentences or paragraphs\n",
        "\n",
        "# Train Word2Vec on the document sentences\n",
        "processed_corpus = [LemNormalize(sent) for sent in sent_tokens]\n",
        "word2vec_model = Word2Vec(sentences=processed_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Generate TF-IDF weights\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "tfidf_vectorizer.fit(sent_tokens)  # Treats each sentence or paragraph as a \"document\" for weighting\n",
        "tfidf_weights = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
        "\n",
        "# Helper to get weighted embeddings\n",
        "def get_weighted_embedding(sentence, model, tfidf_weights):\n",
        "    words = LemNormalize(sentence)\n",
        "    embeddings = [\n",
        "        model.wv[word] * tfidf_weights.get(word, 1.0) for word in words if word in model.wv\n",
        "    ]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Compute embeddings for each sentence/paragraph in the document\n",
        "corpus_embeddings = [get_weighted_embedding(sent, word2vec_model, tfidf_weights) for sent in sent_tokens]\n",
        "\n",
        "# Generate a response using weighted similarity\n",
        "def response(user_response):\n",
        "    chatbot_response = ''\n",
        "    user_embedding = get_weighted_embedding(user_response, word2vec_model, tfidf_weights)\n",
        "\n",
        "    # Calculate cosine similarity between user embedding and corpus embeddings\n",
        "    similarities = cosine_similarity([user_embedding], corpus_embeddings)\n",
        "    idx = np.argmax(similarities)\n",
        "\n",
        "    # Check similarity threshold to filter low-confidence responses\n",
        "    if similarities[0][idx] < 0.3:  # Adjust threshold if needed\n",
        "        chatbot_response = \"I’m sorry! I don’t understand you.\"\n",
        "    else:\n",
        "        chatbot_response = sent_tokens[idx]  # Return the most similar sentence/paragraph\n",
        "\n",
        "    return chatbot_response\n",
        "\n",
        "# Example interaction loop\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Hello! I’m here to help. Type 'bye' to exit.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'bye':\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        print(\"Chatbot:\", response(user_input))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcSXfx3nQgBM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
